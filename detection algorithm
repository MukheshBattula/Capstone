import numpy as np
from sklearn.cluster import DBSCAN

# -------------------- Helper Functions --------------------

def preprocess_data(data):
    """
    Preprocess data: Standardize or normalize if needed.
    """
    # Placeholder: You can add scaling, feature selection, or normalization
    return data

def compute_laplacian_deviation(data, scale_factor=1.0):
    """
    Compute Laplacian Deviation Metric (LDM) for statistical outliers.
    """
    median = np.median(data, axis=0)
    deviations = np.abs(data - median)
    ldm = deviations / scale_factor
    return ldm

def dbscan_clustering(data, eps=0.5, min_samples=5):
    """
    Apply DBSCAN clustering to segment data and identify clusters or noise.
    """
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    labels = dbscan.fit_predict(data)
    return labels

def spbia_set_bounds(data, factor=1.5):
    """
    Statistical Perturbation Bound Identification Algorithm (SPBIA):
    Sets bounds based on clean data to identify potential threats.
    """
    mean = np.mean(data, axis=0)
    std_dev = np.std(data, axis=0)
    lower_bound = mean - factor * std_dev
    upper_bound = mean + factor * std_dev
    return lower_bound, upper_bound

def spbia_flag_outliers(data, bounds):
    """
    Flags samples that fall outside the SPBIA statistical bounds.
    """
    lower_bound, upper_bound = bounds
    flagged_indices = np.where((data < lower_bound) | (data > upper_bound))[0]
    return flagged_indices

# -------------------- Detection Algorithm --------------------

def detect_poisonous_samples(data):
    """
    Combined detection algorithm based on DBSCAN, LDM, and SPBIA.
    """
    # Step 1: Preprocess data
    data = preprocess_data(data)
    
    # Step 2: DBSCAN Clustering for Segmentation
    dbscan_labels = dbscan_clustering(data, eps=0.5, min_samples=5)
    noise_indices = np.where(dbscan_labels == -1)[0]
    print(f"DBSCAN detected {len(noise_indices)} potential outliers.")

    # Step 3: Laplacian Deviation Metric (LDM)
    ldm_scores = compute_laplacian_deviation(data)
    ldm_outliers = np.where(ldm_scores > 2.0)[0]  # Threshold for LDM
    print(f"LDM detected {len(ldm_outliers)} potential outliers.")

    # Step 4: SPBIA for Statistical Perturbation Bounds
    bounds = spbia_set_bounds(data)
    spbia_outliers = spbia_flag_outliers(data, bounds)
    print(f"SPBIA detected {len(spbia_outliers)} potential outliers.")

    # Step 5: Combine Results
    all_outliers = set(noise_indices).union(ldm_outliers).union(spbia_outliers)
    print(f"Combined detection flagged {len(all_outliers)} outliers.")

    # Step 6: Log flagged samples
    return list(all_outliers)

# -------------------- Example Usage --------------------

if __name__ == "__main__":
    # Simulate dataset with clean and malicious samples
    np.random.seed(42)
    clean_data = np.random.normal(0, 1, (100, 2))  # Clean samples
    malicious_data = np.random.normal(5, 1, (10, 2))  # Malicious samples
    data = np.vstack([clean_data, malicious_data])

    # Detect poisonous samples
    outliers = detect_poisonous_samples(data)
    print(f"Flagged outliers (indices): {outliers}")
